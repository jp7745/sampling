{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We are using the Julia 1.9.2 Kernel for this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HDF5\n",
    "using JSON\n",
    "using Plots\n",
    "\n",
    "using GraphicalModelLearning #GML\n",
    "# GML from Los Alamos National Laboratory\n",
    "# https://github.com/lanl-ansi/GraphicalModelLearning.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Workflow\n",
    "\n",
    "The *benchmark performer* shall:\n",
    "1. Select an `instance.<uuid-x>.json` file from the `benchmark_instances` directory.\n",
    "2. Generate samples from the instance using their method and hardware of choice.  The `instance.<uuid-x>.json` file includes the appropriate time limit and number of samples $k$ to generate.\n",
    "3. Write the samples they generated to `solution.<uuid-y>.h5` file in the `benchmark_performer_submissions` folder.  Metadata fields inside of the `solution.<uuid-y>.h5` reference the original `instance.<uuid-x>.json` file and UUID.\n",
    "\n",
    "\n",
    "The *benchmark proctor* shall:\n",
    "1. Select a `solution.<uuid-y>.h5` file and perform verification that the $k$ samples were accurately drawn from the system of interest.\n",
    "2. Write out performance metrics to a `performance_metrics.<uuid-z>.json` file in the `benchmark_performance_metrics` directory.\n",
    "\n",
    "\n",
    "Optionally:  a script will parse `performance_metrics.*.json` files in the `benchmark_performance_metrics` directory and present summary statistics, plots, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Performer Submitted Solution UUID:ee69de1e-3620-11ee-be05-8f4ea6fc831a\n"
     ]
    }
   ],
   "source": [
    "# Acting as the Benchmark Proctor\n",
    "#\n",
    "# Fetch the solution.<uuid-y>.h5 file the benchmark performer submitted\n",
    "\n",
    "\n",
    "# fixed filename/UUID for this example:\n",
    "filename = \"../benchmark_performer_submissions/solution.ee69de1e-3620-11ee-be05-8f4ea6fc831a.EXAMPLE.h5\"\n",
    "instance_uuid = HDF5.h5read(filename, \"solution/instance_uuid\") # original test instance\n",
    "solution_uuid = HDF5.h5read(filename, \"solution/solution_uuid\") # solution submitted by performer\n",
    "println(\"Benchmark Performer Submitted Solution UUID:\",solution_uuid)\n",
    "\n",
    "solution = HDF5.h5read(filename, \"solution\");\n",
    "counts = solution[\"solution_reported\"][\"states_observed_counts\"];\n",
    "states = solution[\"solution_reported\"][\"states_observed\"]\n",
    "\n",
    "# first column is number of observations (counts).  \n",
    "# we organize the samples in this way for compatibility with the GraphicalModelLearning package.\n",
    "samples = hcat(counts, transpose(states));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acting as the Benchmark Proctor\n",
    "#\n",
    "# Read in the adjacency matrix and external field from the ORIGINAL instance.<uuid-x>.json field\n",
    "\n",
    "\n",
    "# fixed filename/UUID for this example:\n",
    "filename = \"../benchmark_instances/instance.\" * instance_uuid * \".EXAMPLE.json\"\n",
    "instance_data = JSON.parsefile(filename)\n",
    "\n",
    "\n",
    "metadata = instance_data[\"metadata\"]\n",
    "graph_data = instance_data[\"graph_data\"]\n",
    "\n",
    "k_B = metadata[\"k_B\"]\n",
    "temperature_T = metadata[\"temperature_T\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n = length(graph_data[\"nodes\"])\n",
    "\n",
    "# reassemble interaction_strength_J matrix from dictionary:\n",
    "interaction_strength_J = zeros(n,n)\n",
    "for edge in graph_data[\"links\"]\n",
    "    i = edge[\"source\"] + 1 # plus 1 because we are going from base0 to base1\n",
    "    j = edge[\"target\"] + 1\n",
    "    w = edge[\"weight\"]\n",
    "    interaction_strength_J[i,j] = w\n",
    "    interaction_strength_J[j,i] = w\n",
    "end\n",
    "\n",
    "external_field_B = zeros(n)\n",
    "for node in graph_data[\"nodes\"]\n",
    "    i = node[\"id\"] + 1 # plus 1 because we are going from base0 to base1\n",
    "    external_field_B[i] = node[\"B\"]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# manually factor in the Boltzmann constant and temperature_T\n",
    "beta = (1/(k_B*temperature_T))\n",
    "\n",
    "interaction_strength_J *= beta;\n",
    "external_field_B *= beta;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acting as the Benchmark Proctor\n",
    "#\n",
    "# Use the GraphicalModelLearning package to estimate \n",
    "# the original graph parameters and topology using \n",
    "# only the samples submitted by the benchmark performer.\n",
    "\n",
    "\n",
    "# The output is in the form of an adjacency matrix for the original graph.\n",
    "# The diagonal of the matrix is the external field strength.\n",
    "\n",
    "GML_method = GraphicalModelLearning.logRISE()\n",
    "learned_adj_matrix = GraphicalModelLearning.learn(samples, GML_method)\n",
    "\n",
    "learned_external_field_B = [learned_adj_matrix[i,i] for i in 1:n];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(learned_adj_matrix, yflip=true)\n",
    "title!(\"Learned Adj. Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(interaction_strength_J, yflip=true)\n",
    "title!(\"The Original Adjacency Matrix (no external field on diagonal)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize all parameters J_ij, B_i to calculate differences\n",
    "\n",
    "learned_param_vector = []\n",
    "original_param_vector = []\n",
    "for i in 1:n\n",
    "    for j in i+1:n \n",
    "        push!(learned_param_vector, learned_adj_matrix[i,j])\n",
    "        push!(original_param_vector, interaction_strength_J[i,j])\n",
    "    end\n",
    "end\n",
    "\n",
    "# a single vector includes all J_ij and B_i terms.\n",
    "for i in 1:n\n",
    "    push!(learned_param_vector, learned_external_field_B[i])\n",
    "    push!(original_param_vector, external_field_B[i])\n",
    "end\n",
    "\n",
    "println(\"length of parameters:\", length(learned_param_vector))\n",
    "\n",
    "plot(xticks=1:3:length(learned_param_vector))\n",
    "plot!(xlabel=\"Parameter Index\")\n",
    "plot!(ylabel=\"Parameter Value\")\n",
    "plot!(learned_param_vector, line=false, marker=:x, label=\"Learned Parameter Reconstruction (GML)\")\n",
    "plot!(original_param_vector, line=false, marker=:circle, label=\"Original Graph Parameters\")\n",
    "\n",
    "\n",
    "# hacky way to show vertical error bars between `learned` and `original` on the plot.\n",
    "x = 0.5*(learned_param_vector - original_param_vector);\n",
    "scatter!(1:length(learned_param_vector), learned_param_vector - x, label=missing, line=true, marker=:vline, yerr=x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have use the `GraphicalModelLearning.jl` package to estimate the parameters of the system from the set of samples that the benchmark performer returned. Call these estimates $\\hat{\\theta}$. We know the true original $\\theta$ parameters of the model from reading the benchmark instance file.  So now we will calculate various norms of the difference $x = \\hat{\\theta} - \\theta$.\n",
    "\n",
    "* $\\ell_0$ ``norm'': sum of the nonzero elements of $x$\n",
    "* $\\ell_1$ norm: sum of the absolute value of all elements of $x$\n",
    "* $\\ell_2$ norm: $\\sqrt{\\sum_i x^2_i}$.  I.e., the Euclidean norm.\n",
    "* $\\ell_\\infty$ norm: the maximum absolute value of all elements of $x$:  $\\text{max}_i \\{ | x_i | \\}$ \n",
    "\n",
    "In all norms, a value close to zero indicates that the model that was reconstructed from the samples closely resembles the true system model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = learned_param_vector - original_param_vector\n",
    "println(\"number of parameters:\",length(learned_param_vector))\n",
    "\n",
    "\n",
    "tolerance = 1e-9\n",
    "ell_0_norm = sum( abs.(x) .>= tolerance*ones(length(learned_param_vector)))\n",
    "println(\"ell_0 norm (small is good): $ell_0_norm\")\n",
    "\n",
    "ell_1_norm = sum( abs.(x) )\n",
    "println(\"ell_1 norm (small is good): $ell_1_norm\")\n",
    "\n",
    "ell_2_norm = sqrt( sum( x.^2 ) )\n",
    "println(\"ell_2 norm (small is good): $ell_2_norm\")\n",
    "\n",
    "ell_inf_norm = maximum( abs.(x) )\n",
    "println(\"ell_inf norm (small is good): $ell_inf_norm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of nodes $n$ in the system is small enough, we also calculate the KL-Divergence metric and the Total Varation Distance.  We need $n$ to be small enough because we will be explicitly calculating the true probability distribution function (PDF) over all $2^n$ possible system states.\n",
    "\n",
    "In the following cells, we calculate the `true_pdf` $Q(s)$  from the original system parameters and the `empirical_pdf` $P(s)$ from the counts of samples/states returned by the benchmark performer.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{KL-divergence} = \\sum_{s \\in \\{-1,+1\\}^n} P(s) \\log  \\left( \\frac{P(s)}{Q(s)} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Total Variation Distance} = \\sup_{s \\in \\{-1,+1\\}^n} | P(s) - Q(s) |\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For both metrics, smaller is better and zero indicates that the distributions are identical.\n",
    "\n",
    "See also\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility functions to switch between spin_config vector and state_index\n",
    "\n",
    "function convert_state_index_to_spin_config(state_index, n)\n",
    "    spin_config = zeros(n)\n",
    "    uint_1 = UInt128(1) #TODO: ensure proper bit width wrt n\n",
    "    for i in 0:n-1\n",
    "        bit = (state_index & (uint_1<<i) != 0)\n",
    "        spin_config[i+1] = 2.0*bit - 1.0\n",
    "    end\n",
    "    return spin_config\n",
    "end;\n",
    "\n",
    "function convert_spin_config_to_state_index(spin_config)\n",
    "    state_index = UInt128(0) #TODO: ensure proper bit width wrt n\n",
    "    uint_1 = UInt128(1)\n",
    "    n = length(spin_config)\n",
    "    for i in 1:n\n",
    "        if spin_config[i] > 0\n",
    "            state_index = state_index | (uint_1<<(i-1))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # state_index will be zero for all spin down (-1)\n",
    "    # state_index will be Int(2^n-1) for all spin up (+1)\n",
    "    return state_index\n",
    "end;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "J = interaction_strength_J\n",
    "for i in 1:n\n",
    "    for j in 1:i\n",
    "        J[i,j] = 0 # set this to an upper triangular matrix with zero diagonal.\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "true_pdf = zeros(2^n)\n",
    "for state_index in 0:2^n-1\n",
    "    spin_config = convert_state_index_to_spin_config(state_index, n)\n",
    "    energy = transpose(spin_config)*J*spin_config + transpose(external_field_B)*spin_config\n",
    "    true_pdf[state_index + 1] = exp(energy) # note that -beta is already factored into J,B\n",
    "end\n",
    "Z = sum(true_pdf);\n",
    "true_pdf *= (1/Z);\n",
    "\n",
    "println(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "empirical_pdf = zeros(2^n)\n",
    "num_unique_states_observed = size(samples)[1]\n",
    "for sample_row in 1:num_unique_states_observed\n",
    "    count = samples[sample_row,1]\n",
    "    spin_config = samples[sample_row,2:end]\n",
    "    # println(count , spin_config)\n",
    "    state_index = convert_spin_config_to_state_index(spin_config)\n",
    "    empirical_pdf[state_index + 1] = count\n",
    "end\n",
    "empirical_pdf *= 1.0/sum(empirical_pdf)\n",
    "\n",
    "\n",
    "println(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "plot(scatter(0:2^n-1,true_pdf, ylim=[0,0.3]))\n",
    "title!(\"True PDF\")\n",
    "xlabel!(\"State Index\")\n",
    "ylabel!(\"Probability of State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "plot(scatter(0:2^n-1, empirical_pdf, ylim=[0,0.3]))\n",
    "title!(\"Empirical PDF from Samples\")\n",
    "xlabel!(\"State Index\")\n",
    "ylabel!(\"Probability of State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "kl_divergence = 0.0\n",
    "for state_index = 0:2^n-1\n",
    "    p = empirical_pdf[state_index + 1]\n",
    "    if p < 1e-9 # p is zero or very close \n",
    "        # the contribution to kl_divergence is zero because lim_{x->0} xlogx = 0.\n",
    "        # TODO: figure out a way to vectorize this math instead of a loop\n",
    "        # but you have to fix up the log(0)=-Inf issue.\n",
    "        continue \n",
    "    end\n",
    "    \n",
    "    q = true_pdf[state_index + 1]\n",
    "    kl_divergence += p*log(p/q)\n",
    "end\n",
    "println(\"kl_divergence (small is good):\",kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert n <= 20\n",
    "\n",
    "total_variation_distance = maximum( abs.(empirical_pdf - true_pdf))\n",
    "println(\"total_variation_distance (small is good):\",total_variation_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the performance metrics are written out to a JSON file `performance_metrics.<uuid-z>.json` in the `benchmark_proctor_performance_metrics` folder.  \n",
    "\n",
    "We skip that part of the example here because we have a Julia script that performs all calculations *in addition to* checking for the latest version of the calculation script.  See `/scripts/benchmark_proctor_evaluation.jl`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
